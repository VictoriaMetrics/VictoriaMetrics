# Data Ingestion

VictoriaLogs supports the following ingestion protocols:

- [Elasticsearch Bulk API / OpenSearch Bulk API](#elasticsearch-bulk-api--opensearch-bulk-api)
- [JSONLine format](#jsonline)

The ingested log entries can be queried according to [these docs](https://docs.victoriametrics.com/VictoriaLogs#querying).

## Collectors

Here is the list of supported collectors and their supported ingestion formats:

| Collector                                                                                  | Elasticsearch                                                                              | JSONLine                                                                                                      |
|--------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------|
| [filebeat](https://docs.victoriametrics.com/VictoriaLogs/collectors.html#filebeat-setup)   | [Yes](https://www.elastic.co/guide/en/beats/filebeat/current/elasticsearch-output.html)    | No                                                                                                            |
| [fluentbit](https://docs.victoriametrics.com/VictoriaLogs/collectors.html#fluentbit-setup) | No                                                                                         | [Yes](https://docs.fluentbit.io/manual/pipeline/outputs/http)                                                 |
| [logstash](https://docs.victoriametrics.com/VictoriaLogs/collectors.html#logstash-setup)   | [Yes](https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html) | [Yes](https://www.elastic.co/guide/en/logstash/current/plugins-outputs-http.html#plugins-outputs-http-format) |
| [vector](https://docs.victoriametrics.com/VictoriaLogs/collectors.html#vector-setup)       | [Yes](https://vector.dev/docs/reference/configuration/sinks/elasticsearch/)                | [Yes](https://vector.dev/docs/reference/configuration/sinks/http/)                                            |

## Data ingestion troubleshooting

VictoriaLogs provides the following command-line flags, which can help debugging data ingestion issues:

- `-logNewStreams` - if this flag is passed to VictoriaLogs, then it logs all the newly
  registered [log streams](https://docs.victoriametrics.com/VictoriaLogs/keyConcepts.html#stream-fields).
  This may help debugging [high cardinality issues](https://docs.victoriametrics.com/VictoriaLogs/keyConcepts.html#high-cardinality).
- `-logIngestedRows` - if this flag is passed to VictoriaLogs, then it logs all the ingested
  [log entries](https://docs.victoriametrics.com/VictoriaLogs/keyConcepts.html#data-model).

VictoriaLogs exposes various [metrics](#monitoring), which may help debugging data ingestion issues:

- `vl_rows_ingested_total` - the number of ingested [log entries](https://docs.victoriametrics.com/VictoriaLogs/keyConcepts.html#data-model)
  since the last VictoriaLogs restart. If this number icreases over time, then logs are successfully ingested into VictoriaLogs.
  The ingested logs can be inspected in logs by passing `-logIngestedRows` command-line flag to VictoriaLogs.
- `vl_streams_created_total` - the number of created [log streams](https://docs.victoriametrics.com/VictoriaLogs/keyConcepts.html#stream-fields)
  since the last VictoriaLogs restart. If this metric grows rapidly during extended periods of time, then this may lead
  to [high cardinality issues](https://docs.victoriametrics.com/VictoriaLogs/keyConcepts.html#high-cardinality).
  The newly created log streams can be inspected in logs by passing `-logNewStreams` command-line flag to VictoriaLogs.

## Data Ingestion Protocols

### Elasticsearch Bulk API / OpenSearch Bulk API

VictoriaLogs supports the [Elasticsearch Bulk API](https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-bulk.html) /
[OpenSearch Bulk API](http://opensearch.org/docs/1.2/opensearch/rest-api/document-apis/bulk/) for data ingestion.

VictoriaLogs endpoint `/insert/elasticsearch/_bulk` have to be used for data ingestion in these formats.

Here are extra query parameters, which can be passed to the `/insert/elasticsearch/_bulk` endpoint:

- The `_msg_field` parameter must contain the field name with the log message generated by collector. This is usually `message` field.
  See [these docs](https://docs.victoriametrics.com/VictoriaLogs/keyConcepts.html#message-field) for details.
- The `_time_field` parameter must contain the field name with the log timestamp generated by collector. This is usually `@timestamp` field.
  See [these docs](https://docs.victoriametrics.com/VictoriaLogs/keyConcepts.html#time-field) for details.
- It is recommended specifying comma-separated list of field names, which uniquely identify every log stream collected by Filebeat, in the `_stream_fields` parameter.
  See [these docs](https://docs.victoriametrics.com/VictoriaLogs/keyConcepts.html#stream-fields) for details.
- If some [log fields](https://docs.victoriametrics.com/VictoriaLogs/keyConcepts.html#data-model) aren't needed,
  then VictoriaLogs can be instructed to ignore them during data ingestion - just pass `ignore_fields` parameter with comma-separated list of fields to ignore.

By default, the ingested logs are stored in the `(AccountID=0, ProjectID=0)` [tenant](https://docs.victoriametrics.com/VictoriaLogs/keyConcepts.html#multitenancy).
If you need storing logs in other tenant, then specify the needed tenant via http headers `AccountID` and `ProjectID`.

### JSONLine

VictoriaLogs supports HTTP API on `/insert/jsonline` endpoint for data ingestion in JSONLine format where
body contains a JSON object in each line (separated by `\n`).

Here is an example:

```http request
POST http://localhost:9428/insert/jsonline/?_stream_fields=stream&_msg_field=log&_time_field=date
Content-Type: application/jsonl

{ "log": { "level": "info", "message": "hello world" }, "date": "2023‐06‐20T15:31:23Z", "stream": "stream1" }
{ "log": { "level": "error", "message": "oh no!" }, "date": "2023‐06‐20T15:32:10Z", "stream": "stream1" }
{ "log": { "level": "info", "message": "hello world" }, "date": "2023‐06‐20T15:35:11Z", "stream": "stream2" }
```

Here are extra query parameters, which can be passed to the `/insert/jsonline` endpoint:

- The `_msg_field` parameter must contain the field name with the log message generated by collector. This is usually `message` field.
  See [these docs](https://docs.victoriametrics.com/VictoriaLogs/keyConcepts.html#message-field) for details.
- The `_time_field` parameter must contain the field name with the log timestamp generated by collector. This is usually `@timestamp` field.
  See [these docs](https://docs.victoriametrics.com/VictoriaLogs/keyConcepts.html#time-field) for details.
- It is recommended specifying comma-separated list of field names, which uniquely identify every log stream collected by Filebeat, in the `_stream_fields` parameter.
  See [these docs](https://docs.victoriametrics.com/VictoriaLogs/keyConcepts.html#stream-fields) for details.
- If some [log fields](https://docs.victoriametrics.com/VictoriaLogs/keyConcepts.html#data-model) aren't needed,
  then VictoriaLogs can be instructed to ignore them during data ingestion - just pass `ignore_fields` parameter with comma-separated list of fields to ignore.

By default, the ingested logs are stored in the `(AccountID=0, ProjectID=0)` [tenant](https://docs.victoriametrics.com/VictoriaLogs/keyConcepts.html#multitenancy).
If you need storing logs in other tenant, then specify the needed tenant via http headers `AccountID` and `ProjectID`.
